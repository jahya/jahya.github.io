<!DOCTYPE html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1.0"><meta name=author content="Andrew McWilliams"><title>Kinecting to the Network</title><link href=http://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css rel=stylesheet><link href="http://fonts.googleapis.com/css?family=Lato:300,400,300italic,400italic" rel=stylesheet type=text/css><link rel=stylesheet href=/stylesheets/style.83cf.css><!--[if lt IE 9]>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.2/html5shiv-printshiv.min.js"></script>
    <![endif]--><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.4f09.png><link rel="shortcut icon" href=/images/favicon.6537.png></head><body id=blog class=content><header role=banner><h1><a href="/"><span class=shift>Andrew</span> M<span class=sub>c</span>Williams</a></h1><nav role=navigation><h2>Navigation</h2><a id=menu-button href=#><i class="fa fa-bars"></i> <i class="fa fa-times"></i></a><ul class=cta><li><a href="/about/">About</a></li><li><a href="/works/">Works</a></li><li><a href="/blog/">Blog</a></li></ul></nav></header><div class=flex-row><main class=left><article role=article itemscope itemtype=http://schema.org/BlogPosting><header><h1>Kinecting to the Network</h1><div class=widgets>Posted on <time itemprop=dateCreated datetime=2011-12-08>Thursday 8 December, 2011</time><ul class=social><li><a href="http://twitter.com/share?text=Kinecting%20to%20the%20Network&amp;url=http://jahya.net/blog/kinecting-to-network&amp;via=hardwarehacklab"><i class="fa fa-twitter-square"></i></a></li><li><a href="http://www.facebook.com/sharer/sharer.php?title=Kinecting%20to%20the%20Network&amp;u=http://jahya.net/blog/kinecting-to-network"><i class="fa fa-facebook-square"></i></a></li><li><a href="http://www.tumblr.com/share?v=3&amp;t=Kinecting%20to%20the%20Network&amp;u=http://jahya.net/blog/kinecting-to-network"><i class="fa fa-tumblr-square"></i></a></li></ul></div></header><div class=post-content><p>Tom and Hayden have been working on grabbing Kinect data, which is basically data about human movement, and sending it out across the network. The graphics server (an Alienware laptop) reads the data from the network and uses it to render an Augmented Reality scene, which is projected up on the wall.</p><table class=tr-caption-container style="margin-left: 1.5em; text-align: center; float: right"><tbody><tr><td style="text-align: center"><a href=http://4.bp.blogspot.com/-5YL2sKF3lBg/TuD-ODcJXKI/AAAAAAAAASE/wfOdaM9fFFc/s1600/SL372350.JPG style="clear:left; float:left;margin-right:1em; margin-right:1em"><img alt="Barney interacting with a Kinect" height=320 width=240 src=http://4.bp.blogspot.com/-5YL2sKF3lBg/TuD-ODcJXKI/AAAAAAAAASE/wfOdaM9fFFc/s320/SL372350.JPG></a></td></tr><tr><td class=tr-caption style="text-align: center">Barney interacting with a Kinect</td></tr></tbody></table><p>The Kinect is a very cool Microsoft device which was designed for the Xbox 360. It's great for mapping realistic human activity into a 3D model in realtime. It has two cameras onboard - one infrared camera for reading depth data, one webcam-style camera for getting a regular video image matrix.</p><p>Tom downloaded the <a href="http://kinectforwindows.org/">Microsoft SDK</a> (there are others, for example <a href=http://www.codeproject.com/Articles/148251/How-to-Successfully-Install-Kinect-on-Windows-Open.aspx>OpenNI/NITE</a>), which you can use to transpose the depth data onto the video. The result is a video image with identifiable humans overlaid (see the image below).</p><p>The Microsoft SDK also contains software to take this further. By analysing data from the camera streams, and using algorithms designed to find human body parts (such as limbs and torsos), the SDK can build an overlay of 3D 'skeletal' data. This means that it works out the points where it thinks the human body parts extend to and draws lines between them to make up a stick man ('skeleton').</p><p>Tom has written a small C# program which uses the SDK to grab skeletal data points and broadcast them across the network. We are using 3 Kinects, each of which can handle 2 skeletons reliably, making a total of up to 6 actors that can interact with the installation.</p><table class=tr-caption-container style="margin-left: auto; margin-right: auto; text-align: center"><tbody><tr><td style="text-align: center"><a href=http://1.bp.blogspot.com/-Df7wJ0_tk2o/TuD-On2k_VI/AAAAAAAAASQ/4ZnqMRkhLYU/s1600/SL372315.JPG><img alt="Kinect depth data" height=150 width=200 src=http://1.bp.blogspot.com/-Df7wJ0_tk2o/TuD-On2k_VI/AAAAAAAAASQ/4ZnqMRkhLYU/s200/SL372315.JPG></a>&nbsp;&nbsp;&nbsp;&nbsp; <a href=http://1.bp.blogspot.com/-qrhIHD_Wjy0/TuEOF5_YaRI/AAAAAAAAASk/rCyh4yqJ2Po/s1600/SL372409_flipped.jpg><img alt="Kinect skeletal data" height=150 src=http://1.bp.blogspot.com/-qrhIHD_Wjy0/TuEOF5_YaRI/AAAAAAAAASk/rCyh4yqJ2Po/s200/SL372409_flipped.jpg width=200></a></td></tr><tr><td class=tr-caption style="text-align: center">The Kinect SDK offers depth data and skeletal data</td></tr></tbody></table><p>Hayden has created an OSC server on the graphics server to pick up the skeletal data points from the network. He then set up a test person renderer (the stick man on the wall, above) in VVVV so that we can fine-tune the Kinect interaction before passing data on to the real 3D patches.</p><p>Data from the 3D scene are in turn formatted and broadcast across the network as more OSC messages, for the sound environment to pick up. The result will be an audio/visual environment which can be controlled solely by moving in front of the Kinects.</p></div></article><ul id=paging class=cta><li><a href=/blog/first-working-day>&lt; Previous post</a></li><li><a href=/blog/responsive-granular-sound>Next post &gt;</a></li></ul></main><aside class=right><nav><header><h1>All posts</h1></header><h2 id=2015-ref>2015</h2><ul><li><a href=/blog/new-site-for-hardware-hack-lab>New Site for Hardware Hack Lab</a></li></ul><h2 id=2014-ref>2014</h2><ul><li><a href=/blog/sound-control-at-future-interfaces>Sound Control at Future Interfaces</a></li><li><a href=/blog/projection-masking-not-projection>Projection Masking, not Projection Mapping</a></li><li><a href=/blog/addon-for-openframeworks-kinect-v2-and>Addon for openFrameworks, Kinect V2 and Mac</a></li><li><a href=/blog/john-cleese-on-creativity>John Cleese on Creativity</a></li><li><a href=/blog/takeaways-from-eyeo-2014>Takeaways from Eyeo 2014</a></li><li><a href=/blog/hardware-hacker-culture-of-new-york>Hardware Hacker Culture of New York</a></li><li><a href=/blog/future-visions-for-human-interaction>Future Visions for Human Interaction</a></li><li><a href=/blog/openbci-nears-its-kickstarter-goal>OpenBCI Nears it's Kickstarter Goal</a></li></ul><h2 id=2013-ref>2013</h2><ul><li><a href=/blog/sound-chamber-2013>Sound Chamber (2013)</a></li><li><a href=/blog/openbci-hackathon-at-thoughtworks>OpenBCI Hackathon at ThoughtWorks</a></li><li><a href=/blog/exploring-depth-video-at-culturehub>Exploring Depth Video at CultureHub</a></li><li><a href=/blog/introduction-to-ibeacons>Introduction to iBeacons</a></li><li><a href=/blog/volumetric-lab-at-culturehub-nyc>Volumetric Lab at CultureHub NYC</a></li><li><a href=/blog/randomness-in-algorithm>Randomness in the Algorithm</a></li><li><a href=/blog/study-existential>Video: Existential</a></li><li><a href=/blog/the-visual-art-of-brian-eno>The Visual Art of Brian Eno</a></li><li><a href=/blog/rgbdtoolkit-sketch-at-sampler>RGBDToolkit Sketch at The Sampler</a></li><li><a href=/blog/the-artist-geek-hybrid>The Artist-Geek Hybrid</a></li><li><a href=/blog/rgbdtoolkit-calibration-tutorial>RGBDToolkit Calibration Tutorial</a></li><li><a href=/blog/how-depth-sensor-works-in-5-minutes>How a Depth Sensor Works - in 5 Minutes</a></li><li><a href=/blog/focal-lengths-and-camera-sensors>Focal Lengths and Camera Sensors</a></li><li><a href=/blog/rgbdtoolkit-visualizer-tutorial>RGBDToolkit Visualizer Tutorial</a></li><li><a href=/blog/rgbdtoolkit-workshop-at-eyebeam>RGBDToolkit Workshop at Eyebeam</a></li><li><a href=/blog/nosql-distilled-to-keynote>NoSQL Distilled to a Keynote!</a></li><li><a href=/blog/paper-prototyping>Paper Prototyping</a></li><li><a href=/blog/git-vs-github>Is Git the Same Thing as Github!?</a></li></ul><h2 id=2012-ref>2012</h2><ul><li><a href=/blog/counterpoint-to-remote>Counterpoint to the Remote</a></li><li><a href=/blog/the-cascading-process>The Cascading Process</a></li><li><a href=/blog/working-with-total-space>Working with Total Space</a></li><li><a href=/blog/residency-begins-at-cac-troy>Residency Begins at CAC Troy</a></li><li><a href=/blog/installation-sketch-at-open-studios>Installation Sketch at Open Studios</a></li><li><a href=/blog/roman-moshenskys-mirror-world>Roman Moshensky's Mirror World</a></li><li><a href=/blog/open-studios-at-i-park>Open Studios at I-Park</a></li><li><a href=/blog/perception-as-creative-process>Perception as a Creative Process</a></li><li><a href=/blog/the-i-park-graveyard>The I-Park Graveyard</a></li><li><a href=/blog/scoping-out-land>Scoping Out the Land</a></li><li><a href=/blog/residency-begins-at-i-park>Residency Begins at I-Park</a></li><li><a href=/blog/residency-at-contemporary-artists-center>Residency at Contemporary Artists Center</a></li><li><a href=/blog/the-shopping-list-for-projection-bombing>First Shopping List for Projection-Bombing</a></li><li><a href=/blog/portable-projection-in-rural-context>Portable Projection in a Rural Context</a></li><li><a href=/blog/stephen-lumentas-sc-textmate-bundle>Stephen Lumenta's SC TextMate Bundle</a></li><li><a href=/blog/adding-openframeworks-addons>Adding OF Addons (ofxSuperCollider)</a></li><li><a href=/blog/setting-up-supercollider-with-textmate>Setting up SuperCollider with TextMate</a></li><li><a href=/blog/switching-to-macbook-pro>Switching to MacBook Pro</a></li><li><a href=/blog/quickref-for-supercollider>QuickRef for SuperCollider</a></li><li><a href=/blog/getting-started-with-supercollider>Getting Started with SuperCollider</a></li><li><a href=/blog/getting-started-with-openframeworks-in>Getting Started with OpenFrameworks</a></li><li><a href=/blog/overtones-harmonics-and-additive>Overtones, Harmonics and Additive Synthesis</a></li><li><a href=/blog/visit-to-cold-spring>Visit to Cold Spring</a></li><li><a href=/blog/i-park-residency>Residency at I-Park</a></li><li><a href=/blog/light-waves>Light Waves</a></li></ul><h2 id=2011-ref>2011</h2><ul><li><a href=/blog/final-exhibition>The Final Exhibition</a></li><li><a href=/blog/playing-with-particles>Playing with Particles</a></li><li><a href=/blog/responsive-granular-sound>Responsive Granular Sound</a></li><li><a href=/blog/kinecting-to-network>Kinecting to the Network</a></li><li><a href=/blog/first-working-day>First Working Day</a></li><li><a href=/blog/designs-for-freemote>Designs for Freemote</a></li><li><a href=/blog/freemote-utrecht>Freemote Utrecht</a></li><li><a href=/blog/untitled-picture-this-2011>Untitled - Picture This (2011)</a></li><li><a href=/blog/wider-context>The Wider Context?</a></li><li><a href=/blog/trading-time-for-space>Trading Time for Space</a></li><li><a href=/blog/talk-at-goldsmiths-digital-studios>Talk at Goldsmiths Digital Studios</a></li><li><a href=/blog/intro-to-marius-watz>Intro to Marius Watz</a></li><li><a href=/blog/practical-guide-to-generative-art>Practical Guide to Generative Art</a></li><li><a href=/blog/installation-at-alpha-ville>Installation at Alpha-Ville</a></li><li><a href=/blog/simple-harmonic-motion>Simple Harmonic Motion</a></li><li><a href=/blog/jaaga-journal-features>Jaaga Journal Features</a></li><li><a href=/blog/gravity-2011>Gravity (2011)</a></li><li><a href=/blog/reflections-2011>Reflections (2011)</a></li><li><a href=/blog/jaaga-sound-lights>Jaaga Sound & Lights</a></li><li><a href=/blog/two-works-for-jaaga-gravity-and-memory>Two Works for Jaaga: Gravity and Reflections</a></li><li><a href=/blog/cosm-collision-detection-and-volume>Cosm, Collision Detection and Volume</a></li><li><a href=/blog/vector-base-amplitude-panning>Vector-Base Amplitude Panning</a></li><li><a href=/blog/intuition-and-direction-of-project>Intuition, and Direction of the Project</a></li><li><a href=/blog/reflections-what-is-jaaga>Reflections: What is Jaaga?</a></li><li><a href=/blog/going-further-with-ambisonics>Going Further with Ambisonics</a></li><li><a href=/blog/introduction-to-ambisonics>Introduction to Ambisonics</a></li><li><a href=/blog/surface-light-sound-installation>Surface (2010)</a></li><li><a href=/blog/running-servo-motor>Servo Motors and Transistors</a></li><li><a href=/blog/spinning-12v-dc-motor>Spinning a 12V DC Motor</a></li><li><a href=/blog/spinning-dc-motor>Spinning a 5V DC Motor</a></li><li><a href=/blog/first-week-at-jaaga>First Week at Jaaga</a></li><li><a href=/blog/presentation-style>Presentation Style</a></li><li><a href=/blog/beginning-jaaga-fellowship>Beginning the Jaaga Fellowship</a></li><li><a href=/blog/brian-eno-role-models-and-direction>Brian Eno, Role Models and Direction</a></li><li><a href=/blog/hype-cycle_17>The Hype Cycle</a></li></ul><h2 id=2010-ref>2010</h2><ul><li><a href=/blog/working-with-3d-space>Working with 3D Space</a></li><li><a href=/blog/technology-and-luck>Technology and Luck</a></li><li><a href=/blog/gallery-types-and-commercial-gallery>Different Types of Gallery</a></li><li><a href=/blog/jason-bruges-studio>Jason Bruges Studio</a></li><li><a href=/blog/unstable-empathy-trust-and>Unstable Empathy & Gaining Trust</a></li><li><a href=/blog/chris-o-two-creative-cultures>Chris O'Shea & Two Creative Cultures</a></li></ul></nav></aside></div><script src=/javascript/script.e2be.js></script></body></html>