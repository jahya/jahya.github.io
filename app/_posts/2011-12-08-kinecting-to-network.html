---
layout: post
bodyid: "blog"
bodyclass: "content"
title: Kinecting to the Network
date: '2011-12-08T19:49:00.003Z'
author: Andrew McWilliams
tags:
- Freemote Threshold
- Kinect
- Feature
- V4W
- Freemote
- C#
- VVVV
- Audio / Visual
modified_time: '2012-05-02T12:48:45.714+01:00'
thumbnail: http://4.bp.blogspot.com/-5YL2sKF3lBg/TuD-ODcJXKI/AAAAAAAAASE/wfOdaM9fFFc/s72-c/SL372350.JPG
blogger_id: tag:blogger.com,1999:blog-1775524623396551680.post-7878656795080549279
blogger_orig_url: http://jahyawords.blogspot.com/2011/12/kinecting-to-network.html
---

<p>Tom and Hayden have been working on grabbing Kinect data, which is basically data about human movement, and sending it out across the network. The graphics server (an Alienware laptop) reads the data from the network and uses it to render an Augmented Reality scene, which is projected up on the wall.</p>   <table class="tr-caption-container" style="margin-left: 1.5em; text-align: center; float: right;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-5YL2sKF3lBg/TuD-ODcJXKI/AAAAAAAAASE/wfOdaM9fFFc/s1600/SL372350.JPG" style="clear:left; float:left;margin-right:1em; margin-right:1em"><img alt="Barney interacting with a Kinect" height="320" width="240" src="http://4.bp.blogspot.com/-5YL2sKF3lBg/TuD-ODcJXKI/AAAAAAAAASE/wfOdaM9fFFc/s320/SL372350.JPG" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Barney interacting with a Kinect</td></tr></tbody></table> <p>The Kinect is a very cool Microsoft device which was designed for the Xbox 360. It's great for mapping realistic human activity into a 3D model in realtime. It has two cameras onboard - one infrared camera for reading depth data, one webcam-style camera for getting a regular video image matrix.</p>

<!--excerpt-ends-->

<p>Tom downloaded the <a href="http://kinectforwindows.org/">Microsoft SDK</a> (there are others, for example <a href="http://www.codeproject.com/Articles/148251/How-to-Successfully-Install-Kinect-on-Windows-Open.aspx">OpenNI/NITE</a>), which you can use to transpose the depth data onto the video. The result is a video image with identifiable humans overlaid (see the image below).</p> <p>The Microsoft SDK also contains software to take this further. By analysing data from the camera streams, and using algorithms designed to find human body parts (such as limbs and torsos), the SDK can build an overlay of 3D 'skeletal' data. This means that it works out the points where it thinks the human body parts extend to and draws lines between them to make up a stick man ('skeleton').</p> <p> Tom has written a small C# program which uses the SDK to grab skeletal data points and broadcast them across the network. We are using 3 Kinects, each of which can handle 2 skeletons reliably, making a total of up to 6 actors that can interact with the installation.</p> <table class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-Df7wJ0_tk2o/TuD-On2k_VI/AAAAAAAAASQ/4ZnqMRkhLYU/s1600/SL372315.JPG"><img alt="Kinect depth data" height="150" width="200" src="http://1.bp.blogspot.com/-Df7wJ0_tk2o/TuD-On2k_VI/AAAAAAAAASQ/4ZnqMRkhLYU/s200/SL372315.JPG" /></a>     <a href="http://1.bp.blogspot.com/-qrhIHD_Wjy0/TuEOF5_YaRI/AAAAAAAAASk/rCyh4yqJ2Po/s1600/SL372409_flipped.jpg"><img alt="Kinect skeletal data" height="150" src="http://1.bp.blogspot.com/-qrhIHD_Wjy0/TuEOF5_YaRI/AAAAAAAAASk/rCyh4yqJ2Po/s200/SL372409_flipped.jpg" width="200" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">The Kinect SDK offers depth data and skeletal data</td></tr></tbody></table> <p> Hayden has created an OSC server on the graphics server to pick up the skeletal data points from the network. He then set up a test person renderer (the stick man on the wall, above) in VVVV so that we can fine-tune the Kinect interaction before passing data on to the real 3D patches.</p> <p>Data from the 3D scene are in turn formatted and broadcast across the network as more OSC messages, for the sound environment to pick up. The result will be an audio/visual environment which can be controlled solely by moving in front of the Kinects.</p>